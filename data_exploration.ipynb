{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_zip_folder(file_type, zip_folder_path, new_folder_path):\n",
    "    '''This function extracts files from a zip folder.\n",
    "    It just extracts the files of a certain type\n",
    "    '''\n",
    "    with ZipFile(zip_folder_path, 'r') as zip_obj:\n",
    "       # Get a list of all archived file names from the zip\n",
    "       list_of_file_names = zip_obj.namelist()\n",
    "       # Iterate over the file names\n",
    "       for file_name in list_of_file_names:\n",
    "           # Check filename endswith csv\n",
    "           if file_name.endswith(f'.{file_type}'):\n",
    "               # Extract a single file from zip\n",
    "               zip_obj.extract(file_name, new_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_from_zip_folder('csv', 'data/Anio201810.zip', 'csv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>H01</th>\n",
       "      <th>V01</th>\n",
       "      <th>...</th>\n",
       "      <th>H20</th>\n",
       "      <th>V20</th>\n",
       "      <th>H21</th>\n",
       "      <th>V21</th>\n",
       "      <th>H22</th>\n",
       "      <th>V22</th>\n",
       "      <th>H23</th>\n",
       "      <th>V23</th>\n",
       "      <th>H24</th>\n",
       "      <th>V24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28079004_1_38</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>2.0</td>\n",
       "      <td>V</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V</td>\n",
       "      <td>5.0</td>\n",
       "      <td>V</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO   ANO  MES  DIA  \\\n",
       "0         28         79         4         1  28079004_1_38  2018    4    1   \n",
       "1         28         79         4         1  28079004_1_38  2018    4    2   \n",
       "2         28         79         4         1  28079004_1_38  2018    4    3   \n",
       "3         28         79         4         1  28079004_1_38  2018    4    4   \n",
       "4         28         79         4         1  28079004_1_38  2018    4    5   \n",
       "\n",
       "   H01 V01  ...  H20 V20  H21 V21  H22 V22  H23 V23  H24 V24  \n",
       "0  2.0   V  ...  2.0   V  2.0   V  3.0   V  4.0   V  3.0   V  \n",
       "1  2.0   V  ...  2.0   V  2.0   V  2.0   V  2.0   V  2.0   V  \n",
       "2  2.0   V  ...  2.0   V  2.0   V  2.0   V  2.0   V  2.0   V  \n",
       "3  2.0   V  ...  2.0   V  2.0   V  2.0   V  2.0   V  2.0   V  \n",
       "4  2.0   V  ...  2.0   V  2.0   V  4.0   V  5.0   V  4.0   V  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('csv_data/abr_mo18.csv', sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4490, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data[data['MAGNITUD'] == 8]['PUNTO_MUESTREO']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_days(dataframe):\n",
    "    '''This function takes the monthly dataframe and checks if there are missing days\n",
    "    for a specific sample spot. If so, it appends a row to the original dataframe with\n",
    "    the info of that day and the validation columns set to N (non validated), to know that\n",
    "    info is not correct (we will correct it later).\n",
    "    '''\n",
    "    year = dataframe.loc[0, 'ANO']\n",
    "    month = dataframe.loc[0, 'MES']\n",
    "    \n",
    "    # First we have to know how many days a specific month has:\n",
    "    _, number_days_month = calendar.monthrange(year, month)\n",
    "    \n",
    "    # We create a list with all the days of that month\n",
    "    list_of_days_of_the_month = list(range(1, number_days_month + 1))\n",
    "    \n",
    "    # We create a list with all the sample spots\n",
    "    sample_spots_list = list(set(dataframe['PUNTO_MUESTREO']))\n",
    "    \n",
    "    for sample_spot in sample_spots_list:\n",
    "        print(f'Checking sample spot: {sample_spot}')\n",
    "        # We create a df with just the info of one spot\n",
    "        sample_spot_df = dataframe[dataframe['PUNTO_MUESTREO'] == sample_spot].reset_index()\n",
    "\n",
    "        # We check if all that days are contained in the spot df\n",
    "        isin_df = pd.Series(list_of_days_of_the_month).isin(list(sample_spot_df['DIA']))\n",
    "        isin_df.index = list_of_days_of_the_month\n",
    "\n",
    "        # Now, if a day is not included, we append a row with its data to the original df\n",
    "        for day, isin in isin_df.iteritems():\n",
    "            if isin == False:\n",
    "                print(f'Day {day}-{month}-{year} missing')\n",
    "                \n",
    "                # We take the first row of the df, but we change the day and the validation columns to 'N'\n",
    "                row_to_append = [sample_spot_df.loc[0, column] for column in sample_spot_df.columns]\n",
    "                row_to_append[8] = day\n",
    "                for i, e in enumerate(row_to_append):\n",
    "                    if e == 'V':\n",
    "                        row_to_append[i] = 'N'\n",
    "                print(row_to_append)\n",
    "                \n",
    "                # We append the row\n",
    "                dataframe = dataframe.append(pd.Series(row_to_append, index=sample_spot_df.columns), ignore_index=True)\n",
    "                print(f'Day {day}-{month}-{year} row added to original dataframe')\n",
    "            \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_dataframe(dataframe, cols_to_drop, cols_remain):\n",
    "    '''This function applies the pandas stack method to make data that is\n",
    "    spread in columns collapse in a single column.\n",
    "    First drops the columns that would not let the stack work properly.\n",
    "    Then sets the columns that do not have to be stacked as the index.\n",
    "    Applies stack method. Finally, resets index.\n",
    "    '''\n",
    "    dataframe = dataframe.drop(columns=cols_to_drop)\n",
    "    dataframe = dataframe.set_index(cols_remain)\n",
    "    dataframe = dataframe.stack().reset_index()\n",
    "    dataframe = dataframe[dataframe[dataframe.columns[-2]] != 'index'].reset_index()\n",
    "    dataframe = dataframe.drop(columns='index')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_col_to_df(df1, df2):\n",
    "    ''' Adds the last column from a dataframe to another dataframe with the same number of rows'''\n",
    "    df1['new_col'] = df2.iloc[:,-1]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_validated_value(dataframe, index, get_next=True):\n",
    "    '''This function gets the next or previous validated row index in a dataframe'''\n",
    "    iterator = 0\n",
    "    next_validated = 'N'\n",
    "    \n",
    "    while next_validated != 'V':\n",
    "        iterator += 1\n",
    "        if get_next:\n",
    "            next_validated = dataframe.loc[index + iterator, 'VALIDADO']\n",
    "            wanted_index = index + iterator\n",
    "        else:\n",
    "            next_validated = dataframe.loc[index - iterator, 'VALIDADO']\n",
    "            wanted_index = index - iterator\n",
    "\n",
    "    return wanted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_non_validated_values(dataframe):\n",
    "    '''This function sets new values to non validated records, based on near values.\n",
    "    It tries to get the nearest next and previous validated values, to assign an average of them.\n",
    "    If it doesn't find a nearest next validated value, it assigns the nearest previous one,\n",
    "    and viceversa.\n",
    "    '''\n",
    "    dataframe = dataframe.sort_values(by=['PUNTO_MUESTREO', 'ANO', 'MES', 'DIA', 'HORA']).reset_index(drop=True)\n",
    "    \n",
    "    sample_spots_list = list(set(dataframe['PUNTO_MUESTREO']))\n",
    "    \n",
    "    for sample_spot in sample_spots_list:\n",
    "        sample_spot_df = dataframe[dataframe['PUNTO_MUESTREO'] == sample_spot]\n",
    "        sample_spot_df_n = sample_spot_df[sample_spot_df['VALIDADO'] == 'N']\n",
    "        \n",
    "        for index, row in sample_spot_df_n.iterrows():\n",
    "            print(f\"Reassigning NO2 value for spot {row['PUNTO_MUESTREO']}, {row['ANO']}-{row['MES']}-{row['DIA']} {row['HORA']}:00\")\n",
    "            try:\n",
    "                next_validated_index = get_next_validated_value(sample_spot_df, index)\n",
    "                \n",
    "                try:\n",
    "                    previous_validated_index = get_next_validated_value(sample_spot_df, index, get_next=False)\n",
    "                    dataframe.loc[index, 'NIVEL_NO2'] = (\n",
    "                        sample_spot_df.loc[next_validated_index, 'NIVEL_NO2'] +\n",
    "                        sample_spot_df.loc[previous_validated_index, 'NIVEL_NO2']\n",
    "                    ) / 2\n",
    "                \n",
    "                except KeyError:\n",
    "                    next_validated_index = get_next_validated_value(sample_spot_df, index)\n",
    "                    dataframe.loc[index, 'NIVEL_NO2'] = sample_spot_df.loc[next_validated_index, 'NIVEL_NO2']\n",
    "            \n",
    "            except KeyError:\n",
    "                next_validated_index = get_next_validated_value(sample_spot_df, index, get_next=False)\n",
    "                dataframe.loc[index, 'NIVEL_NO2'] = sample_spot_df.loc[next_validated_index, 'NIVEL_NO2']\n",
    "                \n",
    "            dataframe.loc[index, 'VALIDADO'] = 'R'\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_df(dataframe):\n",
    "    '''Gets a df, keeps just the NO2 info, splits it into 2 dataframes,\n",
    "    each of them with one of the columns that we want to stack,\n",
    "    joins them into a single dataframe, renames columns and formats HORA column.\n",
    "    The result is a much easier to use dataframe'''\n",
    "    \n",
    "    print(f'Dataframe shape: {dataframe.shape}')\n",
    "    \n",
    "    print('Keeping just NO2 data')\n",
    "    dataframe = dataframe[dataframe['MAGNITUD'] == 8].drop(columns=['MAGNITUD']).reset_index(drop=True)\n",
    "    \n",
    "    print(f'Dataframe shape: {dataframe.shape}')\n",
    "    \n",
    "    print('Adding missing days rows')\n",
    "    # We need a list of the sample spots\n",
    "    list_of_sample_spots = list(set(dataframe['PUNTO_MUESTREO']))\n",
    "    print(f'{len(list_of_sample_spots)} sample spots')\n",
    "    \n",
    "    # We apply the function that add records of missing days\n",
    "    dataframe = add_missing_days(dataframe)\n",
    "    \n",
    "    print(f'Dataframe shape: {dataframe.shape}')\n",
    "    \n",
    "    cols_dimensiones = ['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO', 'ANO', 'MES', 'DIA']\n",
    "    \n",
    "    print('Stacking dataframes')\n",
    "    df_h = get_stacked_dataframe(\n",
    "        dataframe,\n",
    "        cols_remain=cols_dimensiones,\n",
    "        cols_to_drop=[col for col in list(dataframe.columns) if col[0] == 'V']\n",
    "    )\n",
    "    \n",
    "    df_v = get_stacked_dataframe(\n",
    "        dataframe,\n",
    "        cols_remain=cols_dimensiones,\n",
    "        cols_to_drop=[col for col in list(dataframe.columns) if col[0] == 'H']\n",
    "    )\n",
    "    \n",
    "    print('Joining dataframes')\n",
    "    final_df = add_last_col_to_df(df_h, df_v)\n",
    "    \n",
    "    print('Renaming columns')\n",
    "    final_df = final_df.rename(columns={'level_7': 'HORA', 0: 'NIVEL_NO2', 'new_col': 'VALIDADO'})\n",
    "    \n",
    "    print('Formatting HORA column')\n",
    "    final_df['HORA'] = final_df['HORA'].apply(lambda x: int(x[-2:]))\n",
    "    \n",
    "    print('Sorting dataframe by year, month and day')\n",
    "    final_df = assign_non_validated_values(final_df)\n",
    "    print(f'Final dataframe shape: {final_df.shape}')\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (4490, 56)\n",
      "Keeping just NO2 data\n",
      "Dataframe shape: (719, 55)\n",
      "Adding missing days rows\n",
      "24 sample spots\n",
      "Checking sample spot: 28079040_8_8\n",
      "Checking sample spot: 28079027_8_8\n",
      "Checking sample spot: 28079048_8_8\n",
      "Checking sample spot: 28079057_8_8\n",
      "Checking sample spot: 28079038_8_8\n",
      "Checking sample spot: 28079055_8_8\n",
      "Checking sample spot: 28079011_8_8\n",
      "Checking sample spot: 28079060_8_8\n",
      "Checking sample spot: 28079024_8_8\n",
      "Checking sample spot: 28079008_8_8\n",
      "Checking sample spot: 28079018_8_8\n",
      "Day 18-4-2018 missing\n",
      "[150, 28, 79, 18, '28079018_8_8', 2018, 4, 1, 18, 'N', 13.0, 'N', 13.0, 'N', 29.0, 'N', 40.0, 'N', 39.0, 'N', 48.0, 'N', 49.0, 'N', 34.0, 'N', 36.0, 'N', 33.0, 'N', 21.0, 'N', 17.0, 'N', 16.0, 'N', 14.0, 'N', 10.0, 'N', 11.0, 'N', 11.0, 'N', 15.0, 'N', 24.0, 'N', 57.0, 'N', 73.0, 'N', 74.0, 'N', 104.0, 'N']\n",
      "Day 18-4-2018 row added to original dataframe\n",
      "Checking sample spot: 28079054_8_8\n",
      "Checking sample spot: 28079035_8_8\n",
      "Checking sample spot: 28079049_8_8\n",
      "Checking sample spot: 28079036_8_8\n",
      "Checking sample spot: 28079039_8_8\n",
      "Checking sample spot: 28079047_8_8\n",
      "Checking sample spot: 28079059_8_8\n",
      "Checking sample spot: 28079058_8_8\n",
      "Checking sample spot: 28079016_8_8\n",
      "Checking sample spot: 28079056_8_8\n",
      "Checking sample spot: 28079004_8_8\n",
      "Checking sample spot: 28079050_8_8\n",
      "Checking sample spot: 28079017_8_8\n",
      "Dataframe shape: (720, 56)\n",
      "Stacking dataframes\n",
      "Joining dataframes\n",
      "Renaming columns\n",
      "Formatting HORA column\n",
      "Sorting dataframe by year, month and day\n",
      "Reassigning NO2 value for spot 28079040_8_8, 2018-4-10 17:00\n",
      "Reassigning NO2 value for spot 28079038_8_8, 2018-4-9 10:00\n",
      "Reassigning NO2 value for spot 28079038_8_8, 2018-4-9 20:00\n",
      "Reassigning NO2 value for spot 28079055_8_8, 2018-4-26 17:00\n",
      "Reassigning NO2 value for spot 28079011_8_8, 2018-4-10 11:00\n",
      "Reassigning NO2 value for spot 28079060_8_8, 2018-4-11 9:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-6 18:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-12 10:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-18 10:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-18 11:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-18 12:00\n",
      "Reassigning NO2 value for spot 28079024_8_8, 2018-4-24 14:00\n",
      "Reassigning NO2 value for spot 28079008_8_8, 2018-4-9 14:00\n",
      "Reassigning NO2 value for spot 28079008_8_8, 2018-4-10 13:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 1:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 2:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 3:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 4:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 5:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 6:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 7:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 8:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 9:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 10:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 11:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 12:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 13:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 14:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 15:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 16:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 17:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 18:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 19:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 20:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 21:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 22:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 23:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-1 24:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-12 11:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 18:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 19:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 20:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 21:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 22:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 23:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-17 24:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 1:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 2:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 3:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 4:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 5:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 6:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 7:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 8:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 9:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 10:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 11:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 12:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 13:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 14:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 15:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 16:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 17:00\n",
      "Reassigning NO2 value for spot 28079018_8_8, 2018-4-19 18:00\n",
      "Reassigning NO2 value for spot 28079054_8_8, 2018-4-25 11:00\n",
      "Reassigning NO2 value for spot 28079035_8_8, 2018-4-9 13:00\n",
      "Reassigning NO2 value for spot 28079035_8_8, 2018-4-9 19:00\n",
      "Reassigning NO2 value for spot 28079035_8_8, 2018-4-23 12:00\n",
      "Reassigning NO2 value for spot 28079049_8_8, 2018-4-11 12:00\n",
      "Reassigning NO2 value for spot 28079049_8_8, 2018-4-23 13:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-5 23:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-5 24:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 1:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 2:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 3:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 4:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 5:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 6:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 7:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 8:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-6 9:00\n",
      "Reassigning NO2 value for spot 28079039_8_8, 2018-4-9 17:00\n",
      "Reassigning NO2 value for spot 28079059_8_8, 2018-4-12 14:00\n",
      "Reassigning NO2 value for spot 28079059_8_8, 2018-4-27 9:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-20 1:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-20 2:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-20 3:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-20 4:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-20 5:00\n",
      "Reassigning NO2 value for spot 28079056_8_8, 2018-4-24 13:00\n",
      "Reassigning NO2 value for spot 28079004_8_8, 2018-4-9 12:00\n",
      "Reassigning NO2 value for spot 28079050_8_8, 2018-4-11 10:00\n",
      "Reassigning NO2 value for spot 28079017_8_8, 2018-4-11 17:00\n",
      "Reassigning NO2 value for spot 28079017_8_8, 2018-4-24 13:00\n",
      "Final dataframe shape: (17280, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>NIVEL_NO2</th>\n",
       "      <th>VALIDADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>35.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>44.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>38.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>29.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>24.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>46.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>57.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>82.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>85.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>77.0</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PROVINCIA  MUNICIPIO  ESTACION PUNTO_MUESTREO   ANO  MES  DIA  HORA  \\\n",
       "0          28         79         4   28079004_8_8  2018    4    1     1   \n",
       "1          28         79         4   28079004_8_8  2018    4    1     2   \n",
       "2          28         79         4   28079004_8_8  2018    4    1     3   \n",
       "3          28         79         4   28079004_8_8  2018    4    1     4   \n",
       "4          28         79         4   28079004_8_8  2018    4    1     5   \n",
       "5          28         79         4   28079004_8_8  2018    4    1     6   \n",
       "6          28         79         4   28079004_8_8  2018    4    1     7   \n",
       "7          28         79         4   28079004_8_8  2018    4    1     8   \n",
       "8          28         79         4   28079004_8_8  2018    4    1     9   \n",
       "9          28         79         4   28079004_8_8  2018    4    1    10   \n",
       "10         28         79         4   28079004_8_8  2018    4    1    11   \n",
       "11         28         79         4   28079004_8_8  2018    4    1    12   \n",
       "12         28         79         4   28079004_8_8  2018    4    1    13   \n",
       "13         28         79         4   28079004_8_8  2018    4    1    14   \n",
       "14         28         79         4   28079004_8_8  2018    4    1    15   \n",
       "15         28         79         4   28079004_8_8  2018    4    1    16   \n",
       "16         28         79         4   28079004_8_8  2018    4    1    17   \n",
       "17         28         79         4   28079004_8_8  2018    4    1    18   \n",
       "18         28         79         4   28079004_8_8  2018    4    1    19   \n",
       "19         28         79         4   28079004_8_8  2018    4    1    20   \n",
       "20         28         79         4   28079004_8_8  2018    4    1    21   \n",
       "21         28         79         4   28079004_8_8  2018    4    1    22   \n",
       "22         28         79         4   28079004_8_8  2018    4    1    23   \n",
       "23         28         79         4   28079004_8_8  2018    4    1    24   \n",
       "\n",
       "    NIVEL_NO2 VALIDADO  \n",
       "0        21.0        V  \n",
       "1        19.0        V  \n",
       "2        17.0        V  \n",
       "3        24.0        V  \n",
       "4        17.0        V  \n",
       "5        35.0        V  \n",
       "6        40.0        V  \n",
       "7        36.0        V  \n",
       "8        34.0        V  \n",
       "9        35.0        V  \n",
       "10       44.0        V  \n",
       "11       44.0        V  \n",
       "12       38.0        V  \n",
       "13       26.0        V  \n",
       "14       29.0        V  \n",
       "15       22.0        V  \n",
       "16       17.0        V  \n",
       "17       24.0        V  \n",
       "18       32.0        V  \n",
       "19       46.0        V  \n",
       "20       57.0        V  \n",
       "21       82.0        V  \n",
       "22       85.0        V  \n",
       "23       77.0        V  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_reshaped_df(data)\n",
    "data.head(24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
